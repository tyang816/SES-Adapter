#PBS -q ai
#PBS -l walltime=168:00:00
#PBS -l select=1:ncpus=6:ngpus=1:mem=100gb
#PBS -N esm2_650M_05
#PBS -o /home/tanyang/workspace/SES-Adapter/log
#PBS -e /home/tanyang/workspace/SES-Adapter/log

cd /home/tanyang/clash-for-linux-backup-main
bash start.sh
zsh
source ~/.zshrc
cd /home/tanyang/workspace/SES-Adapter
conda activate protssn
proxy_on

pdb_type=AlphaFold2
ablation=MIB_noise_005
plm_model=prot_bert
wandb_run_name=fsss_"$plm_model"_"$pdb_type"_"$ablation"
CUDA_VISIBLE_DEVICES=1 python train.py \
    --plm_model ckpt/$plm_model \
    --num_attention_heads 8 \
    --pooling_method mean \
    --pooling_dropout 0.1 \
    --dataset_config data/CSV/MetalIonBinding/$ablation.json \
    --lr 5e-4 \
    --num_workers 4 \
    --gradient_accumulation_steps 1 \
    --max_train_epochs 50 \
    --max_batch_token 12000 \
    --patience 5 \
    --structure_seqs foldseek_seq,ss8_seq \
    --ckpt_root result \
    --ckpt_dir $plm_model/MIB_structure_token_ablation \
    --model_name $wandb_run_name.pt \
    --wandb \
    --wandb_entity ty_ang \
    --wandb_project adapter \
    --wandb_run_name $wandb_run_name